% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

% align equations to the left
% use larger type; default would be 10pt
\documentclass[fleqn, 11pt]{article}

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they
% provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper,top=20mm,bottom=20mm}
% for example, change the margins to 2 inches all round
% \geometry{margin=2in}
% set up the page for landscape
% \geometry{landscape}
%   read geometry.pdf for detailed page layout information

% support the \includegraphics command and options
\usepackage{graphicx}
\usepackage{wrapfig}

% Activate to begin paragraphs with an empty line rather than an indent
\usepackage[parfill]{parskip}

%%% PACKAGES
% for much better looking tables
\usepackage{booktabs}
% for better arrays (eg matrices) in maths
\usepackage{array}
% very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{paralist}
% adds environment for commenting out blocks of text & for better verbatim
\usepackage{verbatim}
% make it possible to include more than one captioned figure/table in a single
% float
\usepackage{subfig}
% These packages are all incorporated in the memoir class to one degree or
% another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
% (See the fntguide.pdf for font help)
\allsectionsfont{\sffamily\mdseries\upshape}
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
% Put the bibliography in the ToC
\usepackage[nottoc, notlof, notlot]{tocbibind}
% Alter the style of the Table of Contents
\usepackage[titles, subfigure]{tocloft}
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

\usepackage{calc}
\usepackage{lmodern}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathdots}
\usepackage{mathtools}
\usepackage{enumerate}

\usepackage{algorithm,algorithmicx}
\usepackage[noend]{algpseudocode}
\algrenewcommand\alglinenumber[1]{{\sf\footnotesize\texttt{#1}}}

\usepackage{xcolor}
\renewcommand\thefootnote{\textcolor{blue}{\arabic{footnote}}}

\renewcommand{\figurename}{Fig.}
\def\is{\coloneqq}

\usepackage[linguistics]{forest}

\overfullrule=2em

%%% END Article customizations

%%% The "real" document content comes below...

\title{Algoritmos y Estructuras de Datos 3: Gloppi Ya}
\author{Ignacio E. Losiggio (751/17), Federico A. Sabatini (579/17)}
% Activate to display a given date or no date (if empty), otherwise the current
% date is printed
%\date{}

\begin{document}

\maketitle

\tableofcontents

\section{Introducción}

El problema de la mochila consiste en elegir de un conjunto de ítems con peso y
valor los necesarios para llenar una mochila de acuerdo al peso máximo que
puede tolerar buscando al mismo tiempo maximizar el valor de los objetos
elegidos.

\subsection{Formulación del problema}

Dado un espacio de tamaño $W$ (la mochila), y un conjunto de ítems $(x_1, x_2,
\dots, x_n)$ con pesos $(p_1, p_2 \dots x_n)$ y valores $(v_1, v_2 \dots v_n)$
ambos enteros no negativos, hallar un subconjunto de índices que maximice el
valor total sin exceder el peso máximo $W$, es decir:

\begin{enumerate}
	\item $\sum_{\{i \in \text{índices}\}} v_i$ es la respueta
	\item $\sum_{\{i \in \text{índices}\}} p_i \le W$
	\item La respuesta es máxima (no existe otro conjunto que tenga un
	valor mayor y  pese menor o igual a $W$).
\end{enumerate}

\subsection{Ejemplos}

$W = 30$, ítems $=$
\begin{tabular}{l l}
	Peso  & Valor \\ \toprule
	20 & 50 \\
	10 & 5  \\
	30 & 35
\end{tabular} \\
\textbf{Respuesta:} 55 \\
\textbf{Subconjuntos solución:} $\{(20,50), (10,5)\}$

$W = 60$, ítems $=$
\begin{tabular}{l l}
	Peso & Valor \\ \toprule
	45 & 150 \\
	20 & 50 \\
	20 & 40 \\
	20 & 60
\end{tabular} \\
\textbf{Respuesta:} 150 \\
\textbf{Subconjuntos solución:} $\{(45, 150)\}$ ó $\{(20, 50), (20, 40), (20,
60)\}$

Como puede notarse, es posible que exista más de un subconjunto máximo.

\subsection{Pautas de diseño}

El objetivo de este trabajo es mostrar diferentes algoritmos que resuelven el
problema planteado comparando sus ventajas y desventajas. Para esto se
construirán diferentes experimentos buscando respaldar los resultados teóricos
con experimentos apropiados. Por cada algoritmo ofreceremos cotas de
complejidad tanto en tiempo como en memoria.

\section{Algoritmos explorados}

\subsection{Fuerza bruta}

Dado un conjunto de ítems, el máximo valor que cumple la condición de no
exceder el peso máximo de $W$, existe entre uno (o varios) de los subconjuntos
posibles.

Si no conocemos ninguna forma buena de eliminar subconjuntos inútiles entonces
el número total de subconjuntos a revisar es el tamaño del conjunto de partes
de nuestros ítems ($2^n$).

Podemos ofrecer como primer acercamiento un algoritmos iterativo que recorra
todos los subconjuntos posibles, calculando peso y valor y quedándose con el
mejor.

\begin{algorithm}
\caption{Knapsack con fuerza bruta}
\begin{algorithmic}[1]
\Statex
\Function{Knapsack-Dinamica}{$W, \text{items}$}
\State $\text{mejor} \is 0$
\State $c \is 1$
\While{$c < 2^{\#items}$}
	\State $s \is \Call{calcular}{c, \text{items}}$
	\If{$s_{peso} \leq W \land s_{valor} > \text{mejor}$}
		\State mejor $\is s_{valor}$
	\EndIf
	\State $c \is c + 1$
\EndWhile
\State \Return mejor
\EndFunction
\end{algorithmic}
\begin{description}
	\item[\textbf{Complejidad algorítmica:}] $O(n \times 2^n)$
	\item[\textbf{Memoria requerida:}] $O(n)$
\end{description}
\end{algorithm}

En cada ciclo generamos las sumas $s_{valor}$ y $s_{peso}$ del $c$ésimo
conjunto\footnote{$c$ es el índice del conjunto en la enumeración utilizada por
\textsc{calcular}}. Entonces, una enumeración posible es representar la
pertenencia del $i$ésimo ítem con el $i$ésimo dígito de la repres entación en
base 2 de $c$\footnote{Es decir: $items[i] \in \text{conjunto} \iff c \mod 2^i
= 1$.}.

La forma más simple de calcular las sumas es $O(n)$\footnote{Ya que hay que
revisar por cada uno de los $n$ ítems si se encuentra en el conjunto para
sumarlos.}.  Dado que el $c$ recorre todos los valores en el intervalo $[1,2^n
- 1]$ esta suma se calcula $O(2^n)$ veces ofreciéndonos la complejidad mostrada
de $O(n \times 2^n)$.

\subsection{Backtracking}

Otra estrategia consiste en el uso de un algoritmo exploratorio, por cada elemento del problema, bifurcaremos en 2 llamados recurisvos, considerar el elemento en la mochila final (agregar su peso y valor), o no hacerlo.

Repetido el proceso por $n$ elementos, la cantidad de ramas del problema crece de forma exponencial, con un total de $2^n$ llamados. Si nos aseguramos que resolver un llamado es una constante $O(1)$ la complejidad no excedera $O(2^n)$.

Su complejidad espacial tampoco es trivial, ya que necesita realizar un total de n llamados recursivos para haber explorado una de las posibles soluciones, eso es $O(n)$.

Sin embargo, la ventaja de implementarlo de esta manera es que si podemos en base a algún criterio o heurística logramos saber con antelación que una posible solución no cumple las renstricciones o no es óptima, podemos evitar explorarla. Dichas estrategias se denominarán  
podas del problema a partir de ahora. Veremos 2 algoritmos que implementan podas en sus búsquedas.

\subsubsection{Argumentos utilizados por los algoritmos}

Para simplificar la escritura de los algoritmos de backtracking utilizamos un
argumento $s$ que codifica la ``solución parcial'' a mejorar en cada etapa del
algoritmo. 

\subsubsection{Poda por factibilidad}

El primero que veremos requiere un orden de los ítems previo (por peso de forma
creciente) a llamarlo, esto nos supone un coste inicial de $O(n \times \log
n)$. Gracias al orden podemos asegurar que si para un índice $i$ el $i$-ésimo
ítem no puede agregarse a $s$ entonces todos los ítems con índice mayor tampoco
pueden. (dado que su peso es superior)

Es sencillo notar en esta poda que no descartamos soluciones óptimas debido a que solo estamos descartando soluciones cuyos peso total no cumple las renstricciones del problema.

\clearpage

\begin{algorithm}
\caption{Backtracking con poda por factibilidad}
\begin{algorithmic}[1]
\item[\textbf{Inicialización:}]
\item[] \begin{itemize}
	\item[] $p$ los ítems ordenados de menor a mayor según su peso
	\item[] $W$ el peso máximo de la mochila
	\item[] $s$ (solución parcial)
	\begin{itemize}
		\item[] $s_i = 0$ índice actual
		\item[] $s_{valor} = s_{peso} = 0$ (la mochila vacia \O)
		\item[] $s_{pesosCalculados} = \sum_{i = 0}^{\#p - 1} p[i]_{peso}$
	\end{itemize}
\end{itemize}
\Statex
\Function{Knapsack-Factibilidad}{$p, W, s$}
\If{$s_i = \#p$}
	\Comment Caso base
	\State \Return $s_{valor}$
\EndIf
\If{$s_{peso} + s_{pesosCalculados} \leq W$}
	\Comment Agrego todo a la mochila
	\State \Return $s_{valor} + \sum_{i=s_i}^{\#p - 1} p[i]_{valor}$
\EndIf
\If{$s_{peso} + p[s_i]_{peso} > W $}
	\Comment No puedo sumar ningún valor más
	\State \Return $s_{valor}$
\EndIf

\State $\text{con-valor} \is \Call{Knapsack-Optimalidad}{p, W, \text{ considerar } s_i}$
\Comment $s_i \in$ mochila
\State $\text{sin-valor} \is \Call{Knapsack-Optimalidad}{p, W, \text{ no considerar } s_i}$
\Comment $s_i \not\in$ mochila
\State \Return $\Call{max}{\text{con-valor}, \text{sin-valor}}$
\EndFunction
\end{algorithmic}
\begin{description}
	\item[\textbf{Complejidad algorítmica:}] $O(2^n)$
	\item[\textbf{Memoria requerida:}] $O(n)$
\end{description}
\end{algorithm}

Los casos favorables de esta poda se encuentran cuando $W$ resulta mucho más
pequeño o grande que los pesos de todos los ítems, dado que se puede evitar el
analisis de mochilas inviables (\text{6}) o rellenar a la mochila sin
considerar los pesos individuales (\texttt{4}).

\subsubsection{Poda por optimalidad}

La segunda poda que veremos no requiere un ordenamiento previo, en su lugar
debe calcularse $\sum_{i = 0}^{\#p - 1}p[i]_{valor}$ la suma de los valores y ofrecer un candidato ($m$) el cual debe ser una mochila válida.

La idea, es que podemos saber con antelación cual es el valor de la mochila final considerando todos los elementos restantes y si ese valor no excede al candidato $m$, podemos podar, por que esa solución no será óptima.

A la hora de considerar cada ítem podemos utilizar la mochila candidato $m$ y
el valor de nuestros hijos para determinar si somos capaces de
mejorarla\footnote{En caso contrario podemos devolver $m$ ya que sabemos que es
una mochila válda.}. En nuestra implementación previo a correr el algoritmo
ordenamos los ítems para conseguir un $m$ grande lo antes posible.

\clearpage

\begin{algorithm}
\caption{Backtracking con poda por optimalidad}
\begin{algorithmic}[1]
\item[\textbf{Inicialización:}]
\item[] \begin{itemize}
	\item[] $p$ los ítems (preferiblemente ordenados por valor)
	\item[] $W$ el peso máximo de la mochila
	\item[] $s$ (solución parcial)
	\begin{itemize}
		\item[] $s_i = \#p - 1$
		\item[] $s_{valor} = s_{peso} = 0$
		\item[] $s_{valoresRestantes} = \sum_{i = 0}^{\#p - 1} p[i]_{valor}$
	\end{itemize}
	\item[] $m = 0$ la mejor mochila encontrada hasta el momento
\end{itemize}
\Statex
\Function{Knapsack-Optimalidad}{$p, W, m, s$}
\If{$s_i = -1$}
	\Comment Caso base
	\State \Return m
\EndIf
\If{$s_{valor} + s_{valoresRestantes} \leq \text{mejor}$}
	\Comment No puedo mejorar
	\State \Return $m$
\EndIf
\If{$s_{peso} + p[s_i]_{peso} \leq W$}
	\Comment $s_i \in$ mochila
	\State $m \is \Call{Knapsack-Optimalidad}{p, W, m, \text{ considerar } s_i,)}$
\EndIf
\State $m \is \Call{Knapsack-Optimalidad}{p, W, m, \text{ no considerar } s_i}$
\Comment $s_i \not\in$ mochila
\State \Return $m$
\EndFunction
\end{algorithmic}
\begin{description}
	\item[\textbf{Complejidad algorítmica:}] $O(2^n)$
	\item[\textbf{Memoria requerida:}] $O(n)$
\end{description}
\end{algorithm}

\subsection{Meet in Middle}

También podemos encarar el problema con una técnica de búsqueda diferente:
dividimos el problema en 2 partes iguales de dimensión $\frac{n}{2}$,
conseguimos suficiente información para poder resolver nuestro problema y
finalmente construimos la respuesta.

Si construimos $\text{A} = \{a : a \subseteq p\}$ y $\text{B} = \{b : b
\subseteq p\}$ siendo $A$ y $B$ las dos mitades de nuestro conjunto de ítems
entonces los conjuntos solución son todos de la forma $a \bigcup b$\footnote{Si
una solución se encontrase completa en cualquiera de las dos mitades se puede
unir al conjunto vacío de la otra.}. Una vez construidos podemos buscar la
mejor pareja de cualquier subconjunto de una mitad dentro de los subconjuntos
de la otra.

Definiremos entonces que nuestro algoritmo debe realizar los siguientes pasos:

\begin{enumerate}
\item Separar el conjunto de ítems en 2 subconjuntos $A$, $B$. $A$ teniendo los
primeros $\frac{n}{2}$ mochilas posibles de partes de p y $B$ el resto.

\item Construir las mochilas de partes de $A$ y $B$. Es decir los pares $(peso, valor)$. El precio de armar cada uno es de $O(2^{\frac{n}{2}})$.

\item Combinarlos, encontrar las combinaciones $a \bigcup b$ quedándonos con la
mejor de todas. Existen multiples formas de hacerlo:

\begin{enumerate}
	\item Iterar sobre todos los elementos (desestimaremos esta posibilidad
	dado que su complejidad sería $O(2^n)$, no ganaríamos mucho respecto de
	fuerza bruta).

	\item Ordenar $A$ ó $B$, luego descartar conjuntos que no sean óptimos o esten repetidos en el conjunto ordenado y recorrer el otro conjunto linealmente, hallar su mejor combinación con el conjunto ordenado con una búsqueda binaria. Este método nos ofrece una complejidad final
	de $O(n \times 2^{\frac{n}{2}})$.
\end{enumerate}
\end{enumerate}

Veamos la solución en detalle, Ordenar es $O(2^\frac{n}{2} \times \log(2^\frac{n}{2}))$ ya que el conjunto que estoy ordenando es partes de $n$, simplifica a $O(n \times 2^{\frac{n}{2}})$.

Descartar los conjuntos no óptimos, tras haberse ordenado previamente por peso y luego por valor, es lineal sobre partes $O(2^\frac{n}{2}))$ ya que solo debes comparar el conjunto actual contra el anterior para descartarlo\footnote{ Dado un conjunto de peso $x$, se consideran no optimos o repetidos aquellos conjuntos con peso igual o mayor a x, que no lo superen en valor final}, eliminación que es vital para aplicar búsqueda binaria.

Finalmente recorrer el conjunto no ordenado linealmente es $O(2^\frac{n}{2})$ y por cada conjunto se debe encontrar su mejor pareja, dado que el otro conjunto es ordenado esta complejidad es $O(\log{2^\frac{n}{2}})$ que simplifica a $O(n)$ dandonos nuevamente la complejidad $O(n \times 2^{\frac{n}{2}})$.

\begin{algorithm}
\caption{Meet in the middle}
\begin{algorithmic}[1]
\item[\textbf{Inicialización:}]
\item[] \begin{itemize}
	\item[] $p$ conjunto de pares inicial.
	\item[] $p[i]_{peso}$ i-ésimo peso del par p
	\item[] $p[i]_{valor}$ i-ésimo valor del par p
	\item[] $v_{mejor} = 0$
\end{itemize}
\item[\textbf{Funciones auxiliares:}]
\item[] \begin{itemize}
	\setlength\itemsep{0.3em}
	\item[] \Call{mochilas}{$p$} Arma el conjunto de mochilas posibles con
	los ítems de $p$.
	
	\item[] \Call{ordenar}{$p$} Ordenamiendo por comparación con
	complejidad $O(p\log p)$
	
	\item[] \Call{descartar}{$p$} Elimina el $p_i$ si $p_{i-1}$ posee un
	valor mayor a igual o menor peso. Complejidad $O(p)$.

	\item[] \Call{buscar}{$p, k$} Búsqueda binaria, devuelve la última
	mochila de peso $k$ o la última con un peso menor.
\end{itemize}
\Statex
\Function{Knapsack-MeetInTheMiddle}{$p, w$}
\State $Izq$ $\is \Call{mochilas}{p[0:\frac{n}{2}]}$
\State $Der$ $\is \Call{mochilas}{p[\frac{n}{2}:n]}$
\Comment Armo los subconjuntos

\State $Der$ $\is \Call{ordenar}{\text{der}}$
\Comment Ordeno uno de los 2 subconjuntos
\State $Der$ $\is \Call{descartar}{\text{der}}$
\Comment Elimino repetidos o no óptimos

\For{$(a \in Izq)$}
	\If{$a_{peso} \leq w$}
	\State $b \is \Call{buscar}{Der, w - a_{peso}}$
		\If{$a_{peso} + b_{peso} > v_{mejor}$}
			\State  $v_{mejor} \is a_{peso} + b_{peso} > $
		\EndIf
	\EndIf
\EndFor
\State \Return $v_{mejor}$
\EndFunction
\end{algorithmic}
\begin{description}
	\item[\textbf{Complejidad algorítmica:}] $O(n \times 2^{\frac{n}{2}})$
	\item[\textbf{Memoria requerida:}] $O(2^{\frac{n}{2}})$
\end{description}
\end{algorithm}

\subsection{Programación dinámica}

El algoritmo de programación dinámica hace uso de las técnicas exploratorias de
backtracking. A partir de un elemento realizaremos dos llamados recursivos
considerando si agregarlo o no. La diferencia que lo distingue de backtracking
es que almacenaremos las decisiones tomadas para no tener que volver a
calcularlas.

Nuestros subproblemas son las mochilas con los primeros $i$ elementos ($i \le
\#\text{items}$) y un peso máximo $w'$ ($w' \le W$). Podemos notar que si
tenemos todas las mochilas $(i' < i, w'' \le w')$ entonces nuestro problema se
reduce a determinar si el mayor valor se obtiene utilzando el $i$-ésimo
elemento (dado que no se exceda en peso) o ignorándolo.

Construiremos un algoritmo \emph{top-down} (consideramos el problema completo y
lo dividimos hasta llegar a problemas triviales) con dos partes, un algoritmo
recursivo simple y la memoización de sus resultados intermedios. Para esto optaremos como estructura inicializar una matriz, de $n$ filas con $W$ columnas.

Notar que mientras el algoritmo recursivo simple sea correcto siempre y cuando la memoización no pise información relevante, mantendrá su correctitud.

Finalmente una vez reducido el problema a la construcción de una mochila de $0$ elementos
está claro que el mejor valor posible es $0$. Este será nuestro caso base.

\begin{algorithm}
\caption{Knapsack con programación dinámica}
\begin{algorithmic}[1]
\item[\textbf{Inicialización:}]
\item[] \begin{itemize}
	\item[] $i = \#p - 1$
	\item[] $\text{restante} = W$
	\item[] $p$ la lista de ítems a considerar
	\item[] $mem[n][W]$ inicialmente $\bot$ en cada celda
\end{itemize}
\Statex
\Function{Knapsack-Dinamica}{$i, \text{restante}, p, mem$}
\If{$i < 0$}
	\State \Return $0$
\Comment Casos base
\EndIf
\If{$mem[i][\text{restante}] \neq \bot$}
	\State	\Return $mem[i][\text{restante}]$
	\Comment Memoización
\EndIf
\State $\text{sin} \is \Call{Knapsack-Dinamica}{i - 1, r, p}$
\Comment $p[i] \not \in \text{mochila}$
\If{$p[i]_{peso} \le \text{restante}$}
	\State $\text{con} \is p[i]_{valor} + \Call{Knapsack-Dinamica}{i - 1, r - p[i]_{peso}, p}$
	\Comment $p[i] \in \text{mochila}$
\Else
	\State $\text{con} \is 0$
\EndIf
\State $mem[i][\text{restante}] \is \Call{max}{\text{sin}, \text{con}}$
\Comment Guardo el mejor de ambos
\State \Return $mem[i][\text{restante}]$
\EndFunction
\end{algorithmic}
\begin{description}
	\item[\textbf{Complejidad algorítmica:}] $O(n \times W)$
	\item[\textbf{Memoria requerida:}] $O(n \times W)$
\end{description}
\end{algorithm}

En un principio inicializamos $mem$ como $\bot$ lo que cuesta $O(n \times W)$.
Por cada valor de $i$ no trivial se realizarán a lo sumo $2i$ llamadas
recursivas, si $i > W$ tendremos superposición de subproblemas\footnote{Dado
que no realizamos llamadas con peso negativo y que lo único que diferencia un
subproblema de otro es el par $(i, w')$.} por lo que por cada $i$ realizaremos
a lo sumo $W$ cálculos. Entonces para cada $i$ tenemos una complejidad de
$O(W)$ y $\sum_{i=0}^{n} O(W) = O(n \times W)$.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.8\textwidth]{{fotos/pdf.dinamica}.pdf}
\caption{Llamadas recursivas sobre \texttt{casos/pdf.in}. Las líneas punteadas
indican valores ya calculados.}
\end{center}
\end{figure}

\clearpage

\section{Experimentación}

\begin{itemize}
\item Se repite cada prueba 50 veces. Se calcula el promedio.

\item Se dispone de un tiempo límite de 30 segundos por cada prueba (es decir,
el máximo tiempo de procesamiento por un caso de prueba es 25 minutos).

\item Cada experimentación consta de 250 casos de prueba.

\item los datasets en cada prueba son elegidos uniformemente.
\end{itemize}

\subsubsection{Experimento A}

\begin{wrapfigure}{R}[2cm]{0.45\linewidth}
\vspace{-50pt}
\includegraphics[width=\linewidth]{{fotos/exp.a.fuerza_bruta}.pdf}
\caption{Fuerza bruta}
\includegraphics[width=\linewidth]{{fotos/exp.a.backtracking_fact}.pdf}
\caption{Backtracking (factibilidad)}
\includegraphics[width=\linewidth]{{fotos/exp.a.backtracking_opt}.pdf}
\caption{Backtracking (optimalidad)}
\includegraphics[width=0.45\textwidth]{{fotos/exp.a.dinamica}.pdf}
\caption{Programación dinámica}
\end{wrapfigure}

Nuestro primer experimento tiene como objetivo ver cómo se relaciona la
cantidad de ítems a procesar con el tiempo que tarda cada lagoritmo en
procesarlos. Para este fin usaremos una entre 15 y 24 ítems y para evitar los
casos favorables de las podas de backtracking el peso máximo será la mitad del
peso total a procesar. Cada peso y valor estará entre 0 y 100.

\begin{center}
$n \in [15; 24]; W=\frac{\sum p_i}{2}; 0 \leq p_i, v_i \leq 100$
\end{center}

Los resultados fueron los esperables para casi todos los algoritmos exceptuando
el caso de la poda de optimalidad. Es probable que ésta esté podando de manera
muy agresiva haciendo que la complejidad promedio esté alrededor de
$2^\frac{n}{2}$. El gráfico del algoritmo de programación dinámica es
particular pero dado que su complejidad depende tanto de $n$ como de $W$ no se
puede plotear mucho mejor\footnote{Probablemente una serie de boxplots hubiera
sido lo más acertado para ese gráfico en particular.}.

\begin{center}
\includegraphics[width=0.45\textwidth]{{fotos/exp.a.mitm}.pdf}
\captionof{figure}{Meet in the Middle}
\end{center}

\subsubsection{Experimento B}

Para analizar más a fondo los casos favorables y desfavorable de nuestros
algoritmos de backtracking construimos tests variando $n$ y $W$. $W$ es un
valor aleatorio menor o igual a la suma de todos los pesos (un $W$ muy alto es
trivial de resolver para las podas contruídas).

\begin{center}
$n \in [25; 70]; W \in [2; \sum p_i]; 0 \leq p_1, v_i \leq 100$
\end{center}

\clearpage

Cada punto en los gráficos a continuación es el promedio de 50 corridas de un
caso de prueba. Los puntos grises son casos que no pudimos evaluar debido al
tiempo límite de 30 segundos por corrida. El script que genera estos gráficos
puede encontrarse  en \texttt{scripts/experimento\_b.plot}.

\vspace{1em}
\hspace{-3cm}
\begin{minipage}{1.4\textwidth}
\begin{minipage}{0.33\textwidth}
\centering
\includegraphics[width=\linewidth]{{fotos/exp.b.backtracking_fact}.pdf}
\captionof{figure}{Backtracking (factibilidad)}
\end{minipage}
\begin{minipage}{0.33\textwidth}
\centering
\includegraphics[width=\linewidth]{{fotos/exp.b.backtracking_opt}.pdf}
\captionof{figure}{Backtracking (optimalidad)}
\end{minipage}
\begin{minipage}{0.33\textwidth}
\centering
\includegraphics[width=\linewidth]{{fotos/exp.b.mitm}.pdf}
\captionof{figure}{Meet in the Middle}
\end{minipage}
\end{minipage}

Puede verse que tanto la poda por factibilidad cómo la poda por optimalidad
logran resolver valores de $n$ dónde meet-in-the-middle se queda sin memoria o
tiene que operar con subconjuntos demasiado grandes. Sin embargo sólo son
capaces de resolver éstos problemas para combinaciones de $n$ y $W$ dónde la
solución no requiera explorar mochilas de demasiados elementos.

\subsubsection{Experimento C}

Cómo el experimento A resultó muy pequeño para mostrar el comportamiento del
algoritmo de programación dinámica decidimos constuir casos de test mucho más grandes. Dado que la complejidad de teórica de programación dinámica es $O(n \times W)$ se consideró que experimentar con un set donde $n = W$ sería razonable esperar un crecimiento cuadrático.

\begin{center}
$n = W \in [100; 1000]; 0 < p_i < \frac{W}{2}; 1 \leq v_i \leq 5000$
\end{center}

\begin{figure}[h]
\includegraphics{{fotos/exp.c.dinamica}.pdf}
\caption{Programación Dinámica}
\end{figure}

\clearpage

\section{Conclusión}

Hemos considerado cómo resolver el problema de la mochila con diferentes
métodologias, así como hemos buscado identificar la complejidad en tiempo y
memoria requerida y aplicado heúristicas que busquen podar y reducir el espacio
de nuestro problema.

Tras someter a nuestros algoritmos a extensas pruebas. Los resultados mas
destacables son los siguientes:

\begin{enumerate}
	\item La poda por optimalidad puede construír una buena mochila con la
	que podar rápidamente, gracias a esto muestra un rendimiento superior a
	Meet-in-the-Middle en las condiciones
	adecuadas\footnote{Meet-in-the-Middle fracasan rotundamente dado un $n$
	suficientemente largo pero la poda por optimalidad puede construir una
	solución en ciertas situaciones.} pese a que éste tenga una complejidad
	teórica mejor.

	\item El algoritmo de memoria dinámica tuvo un rendimiento
	extremadamente rápido en comparación con los otros, mantuvo un consumo
	de memoria menor que Meet-in-the-Middle aunque mayor que los algoritmos
	de backtracking que realizan\\búsquedas exploratorias y poseen un
	consumo lineal.
	
	\item La poda por factibilidad, mostró ser poco efectiva en casos de
	$n$ grande, lo cual se debe en gran medida a que ésta se realiza en las
	ramas más bajas del árbol de ejecución. La poda solo muestra
	efectividad para casos en los que $W$ es extremadamente bajo o
	excesivamente alto respecto del peso de los ítems.
\end{enumerate}

\section{Referencias:}
\begin{itemize}
	\item[] \textit{Computing partitions with applications to the knapsack
	- Ellis Horowitz and Sartaj Sahni.}
\end{itemize}

\end{document}
